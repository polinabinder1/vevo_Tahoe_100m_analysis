{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3c582b",
   "metadata": {},
   "source": [
    "Process anndata files and convert them to the appropriate format. We only use gene names that are in the geneformer vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155274f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bionemo.core.data.load import load\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "vocab_data_path: Path = (\n",
    "        load(\"single_cell/testdata-20241203\") / \"cellxgene_2023-12-15_small_processed_scdl\" / \"train\" / \"geneformer.vocab\"\n",
    "    )\n",
    "with open(vocab_data_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    gene_list = set(data['vocab'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6151d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from bionemo.core import BIONEMO_CACHE_DIR\n",
    "input_dir = \"/workspaces/bionemo-framework/adata\" #Location of the h5ad file or files\n",
    "\n",
    "# The expected input is that the feature_ids will be a column in .var\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".h5ad\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # Load AnnData object\n",
    "            adata = ad.read_h5ad(file_path)\n",
    "\n",
    "            adata.var['feature_id'] = adata.var.index\n",
    "            mask = adata.var['feature_id'].isin(gene_list)\n",
    "            adata = adata[:, mask]\n",
    "            non_zero_mask = (adata.X != 0).sum(axis=1).A1 > 0 if isinstance(adata.X, np.matrix) else (adata.X != 0).sum(axis=1) > 0\n",
    "            adata = adata[non_zero_mask]\n",
    "\n",
    "            adata.write(file_path)\n",
    "\n",
    "\n",
    "cleanup: bool = True\n",
    "notebook_workdir = BIONEMO_CACHE_DIR / \"notebook_tutorials\" / \"geneformer_classification\"\n",
    "if cleanup and notebook_workdir.exists():\n",
    "    shutil.rmtree(notebook_workdir)\n",
    "notebook_workdir.mkdir(parents=True, exist_ok=True)\n",
    "data_dir = notebook_workdir / \"scdl_dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc259420",
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert_h5ad_to_scdl --data-path {input_dir} --save-path {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2ce4b",
   "metadata": {},
   "source": [
    "Download geneformer models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.core.data.load import load\n",
    "\n",
    "\n",
    "# 106m checkpoint\n",
    "geneformer_106m = load(\"geneformer/106M_240530:2.0\")\n",
    "# 10m checkpoint\n",
    "geneformer_10m = load(\"geneformer/10M_240530:2.0\")\n",
    "# 10m bionemo2 trained checkpoint\n",
    "geneformer_10m_bnmo2 = load(\"geneformer/10M_241113:2.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20967d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from bionemo.core import BIONEMO_CACHE_DIR\n",
    "\n",
    "\n",
    "cleanup: bool = True\n",
    "notebook_workdir = BIONEMO_CACHE_DIR / \"notebook_tutorials\" / \"geneformer_celltype_classification\"\n",
    "if cleanup and notebook_workdir.exists():\n",
    "    shutil.rmtree(notebook_workdir)\n",
    "notebook_workdir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path_10m = notebook_workdir / \"results_10m.pt\"\n",
    "\n",
    "result_path_10m_bnmo2 = notebook_workdir / \"results_10m_bnmo2.pt\"\n",
    "results_path_10m_random = notebook_workdir / \"results_10m_randomweights.pt\"\n",
    "result_path_106m = notebook_workdir / \"results_106m.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0def10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!infer_geneformer \\\n",
    "    --data-dir {data_dir} \\\n",
    "    --checkpoint-path {geneformer_106m} \\\n",
    "    --results-path {result_path_106m} \\\n",
    "    --micro-batch-size 32 \\\n",
    "    --seq-len 2048 \\\n",
    "    --num-dataset-workers 10 \\\n",
    "    --num-gpus 1 \\\n",
    "    --include-input-ids \\\n",
    "    --include-unrecognized-vocab-in-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cea996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "infer_Xs_106m = torch.load(result_path_106m / \"predictions__rank_0.pt\")[\"embeddings\"].float().cpu().numpy()\n",
    "assert len(adata) == len(infer_Xs_106m), (len(adata), len(infer_Xs_106m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b778290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we look at our dataset, how is the distribution of cell counts? Its clear that certain celltypes dominate the dataset, this is good to keep in mind when investigating models.\n",
    "#  we expect the macro averages and F1-score to be the most reliable metrics for overall performance.\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "infer_metadata = adata.obs\n",
    "labels = infer_metadata[\"cell_line\"].values\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "ax = sb.barplot(x=label_counts.keys(), y=label_counts.values())\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\", fontsize = 6)\n",
    "ax.set_title(\"Cell type counts for classification dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4154a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we assign integer labels to each of our strings. These do not need to be transformed into one-hot vectors as Random Forest is non-parametric.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(labels)\n",
    "print(integer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def plot_cm(cm, labels=label_encoder.classes_):\n",
    "    \"\"\"Helper function for visualizing accuracy across labels.\"\"\"\n",
    "    # # Example confusion matrix (replace with your actual data)\n",
    "    # _ = np.random.rand(31, 31)\n",
    "\n",
    "    # Define the bins and the color map\n",
    "    # bounds = np.arange(0.0, 1.1, 0.1)\n",
    "    # cmap = ListedColormap(sb.color_palette(\"RdYlBu_r\", len(bounds) - 1))\n",
    "    # norm = BoundaryNorm(boundaries=bounds, ncolors=len(bounds) - 1, clip=True)\n",
    "\n",
    "    # _ = sb.heatmap(cm / cm.sum(axis=0),cmap=cmap, norm=norm, cbar_kws={\"ticks\": bounds}, linewidths=0.5, linecolor='black', xticklabels=labels, yticklabels=labels)\n",
    "    _ = sb.heatmap(\n",
    "        cm / cm.sum(axis=0),\n",
    "        cmap=sb.color_palette(\"Blues\", as_cmap=True),\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        linewidth=0.1,\n",
    "        linecolor=\"lightgrey\",\n",
    "        #xticklabels=labels,\n",
    "        #yticklabels=labels,\n",
    "    )\n",
    "    #pyplot.xticks(rotation=45, ha=\"right\")\n",
    "    # _ = pyplot.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(data, labels, use_pca=True):\n",
    "    \"\"\"Run the accuracy, precision, recall, and F1-score benchmarks.\n",
    "\n",
    "    Args:\n",
    "        data: (R, C) contains the single cell expression (or whatever feature) in each row.\n",
    "        labels: (R,) contains the string label for each cell\n",
    "        use_pca: whether to fit PCA to the data.\n",
    "\n",
    "    Returns:\n",
    "        results_out: (dict) contains the accuracy, precision, recall, and F1-score for each class.\n",
    "        conf_matrix: (R, R) contains the confusion matrix.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        confusion_matrix,\n",
    "        f1_score,\n",
    "        make_scorer,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        roc_auc_score,\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_validate\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    np.random.seed(1337)\n",
    "    # Define the target dimension 'n_components'\n",
    "    n_components = 10  # for example, adjust based on your specific needs\n",
    "\n",
    "    # Create a pipeline that includes Gaussian random projection and RandomForestClassifier\n",
    "    if use_pca:\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"projection\", PCA(n_components=n_components)),\n",
    "                (\"classifier\", RandomForestClassifier(class_weight=\"balanced\")),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pipeline = Pipeline([(\"classifier\", RandomForestClassifier(class_weight=\"balanced\"))])\n",
    "\n",
    "    # Set up StratifiedKFold to ensure each fold reflects the overall distribution of labels\n",
    "    #cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "\n",
    "    predictions = cross_val_predict(pipeline, data, labels) #, cv=cv)\n",
    "\n",
    "    # v Return confusion matrix and metrics.\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_106M = run_benchmark(infer_Xs_106m, integer_labels, use_pca=False)\n",
    "plot_cm(cm_106M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6eaff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
